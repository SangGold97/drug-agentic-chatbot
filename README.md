# Drug Agentic Chatbot

A sophisticated agentic chatbot system for drug-related queries using RAG (Retrieval-Augmented Generation) and multi-agent architecture.

## Architecture

The system is built with a modular architecture consisting of:

- **Database Layer**: Vector database (Milvus) and metadata database (PostgreSQL)
- **Tools & Services**: Core algorithms and LLM services
- **Worker Nodes**: High-level business logic workers
- **Workflows**: LangGraph-based state machines for complex processes
- **API Gateway**: FastAPI endpoints for external access

## Features

- ðŸ¤– **Multi-Agent System**: Specialized workers for different tasks
- ðŸ§  **RAG (Retrieval-Augmented Generation)**: Combines vector search with web search
- ðŸ”„ **Iterative Reflection**: Self-improving context with follow-up queries
- ðŸŒ **Web Integration**: Real-time web search for latest information
- ðŸ’¬ **Streaming Responses**: Real-time answer generation
- ðŸ¥ **Medical Domain**: Specialized for drug and healthcare information
- ðŸŒ **Multilingual**: Vietnamese and English support

## Prerequisites

- Python 3.9+
- Docker and Docker Compose
- At least 8GB RAM (for local LLM models)
- 10GB+ free disk space (for models and databases)

## Quick Start

### 1. **Setup Environment**
```bash
cd drug-agentic-chatbot
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. **Start Databases**
```bash
cd database
docker-compose up -d
```

### 3. **Configure Environment**
Copy `.env` file and adjust settings as needed:
```bash
cp .env.example .env
# Edit .env with your configurations
```

### 4. **Index Knowledge Base**
```bash
python -c "
from core import Orchestrator
orchestrator = Orchestrator()
result = orchestrator.run_indexing('data/knowledge_base.csv')
print(f'Indexed {result[\"document_count\"]} documents')
"
```

### 5. **Start API Server**
```bash
python run_api.py
# Or using uvicorn directly:
# uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

### 6. **Test the API**
```bash
python test_api.py
```

## API Endpoints

### **Documentation**
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### **Main Endpoints**
- `POST /qa` - Question & Answer
- `POST /qa/stream` - Streaming Q&A 
- `POST /index` - Index knowledge base
- `GET /health` - Health check
- `GET /status` - System status

### **Example Usage**

#### **Q&A Request**
```bash
curl -X POST "http://localhost:8000/qa" \
     -H "Content-Type: application/json" \
     -d '{
       "query": "TÃ¡c dá»¥ng phá»¥ cá»§a paracetamol lÃ  gÃ¬?",
       "user_id": "user123",
       "conversation_id": "conv456"
     }'
```

#### **Streaming Q&A**
```bash
curl -X POST "http://localhost:8000/qa/stream" \
     -H "Content-Type: application/json" \
     -d '{
       "query": "Paracetamol cÃ³ tÆ°Æ¡ng tÃ¡c vá»›i thuá»‘c nÃ o?",
       "user_id": "user123"
     }'
```

#### **Index Knowledge Base**
```bash
curl -X POST "http://localhost:8000/index" \
     -H "Content-Type: application/json" \
     -d '{"csv_file_path": "data/knowledge_base.csv"}'
```

## Project Structure

```
drug-agentic-chatbot/
â”œâ”€â”€ api/                    # FastAPI gateway
â”‚   â”œâ”€â”€ main.py            # Main API application
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ core/                   # Orchestrator and workflows
â”‚   â”œâ”€â”€ orchestrator.py    # Main coordinator
â”‚   â””â”€â”€ workflows/         # LangGraph workflows
â”œâ”€â”€ database/              # Database managers
â”‚   â”œâ”€â”€ postgres_manager.py
â”‚   â”œâ”€â”€ milvus_manager.py
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ tools_services/        # Core tools and LLM services
â”‚   â”œâ”€â”€ embedding_tool.py
â”‚   â”œâ”€â”€ rerank_tool.py
â”‚   â”œâ”€â”€ vector_search_tool.py
â”‚   â”œâ”€â”€ web_search_tool.py
â”‚   â””â”€â”€ llm_services/
â”œâ”€â”€ workers/               # Business logic workers
â”‚   â”œâ”€â”€ intent_classification_worker.py
â”‚   â”œâ”€â”€ query_augmentation_worker.py
â”‚   â”œâ”€â”€ retrieval_worker.py
â”‚   â”œâ”€â”€ reflection_worker.py
â”‚   â”œâ”€â”€ q_and_a_worker.py
â”‚   â”œâ”€â”€ save_conversation_worker.py
â”‚   â””â”€â”€ indexing_worker.py
â”œâ”€â”€ data/                  # Knowledge base data
â”œâ”€â”€ run_api.py            # API startup script
â”œâ”€â”€ test_api.py           # API test script
â””â”€â”€ requirements.txt      # Dependencies
```

## Development Status

âœ… **Phase 1**: Database foundation and basic structure  
âœ… **Phase 2**: Tools and services implementation  
âœ… **Phase 3**: Worker nodes development  
âœ… **Phase 4**: Workflow orchestration  
âœ… **Phase 5**: API gateway and integration  

## Workflow Process

```mermaid
graph TD
    A[User Query] --> B[Intent Classification]
    B --> C{Medical Intent?}
    C -->|Yes| D[Query Augmentation]
    C -->|No| E[General Response]
    D --> F[Parallel Retrieval]
    F --> G[Vector Search]
    F --> H[Web Search]
    G --> I[Rerank & Merge]
    H --> I
    I --> J[Reflection]
    J --> K{Context Sufficient?}
    K -->|No| L[Follow-up Search]
    L --> I
    K -->|Yes| M[Answer Generation]
    M --> N[Save Conversation]
    N --> O[Stream Response]
```

## Models Used

- **Embedding**: `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
- **Reranking**: `jinaai/jina-reranker-v2-base-multilingual`
- **Query Augmentation**: `google/flan-t5-base`
- **Web Summarization**: `google/flan-t5-large`
- **Reflection**: `Qwen/Qwen2.5-1.5B-Instruct`
- **Final Answer**: `MedGemma3-4b-it`

All models run locally with 4-bit quantization for efficiency.

## Production Deployment

### **Using Docker**
```bash
# Build image
docker build -t drug-agentic-chatbot .

# Run with docker-compose
docker-compose up -d
```

### **Using Gunicorn**
```bash
pip install gunicorn
gunicorn api.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

## Monitoring & Logging

- Health check endpoint: `/health`
- Comprehensive logging throughout the system
- Performance metrics in API responses
- Error handling with detailed messages

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## License

MIT License
